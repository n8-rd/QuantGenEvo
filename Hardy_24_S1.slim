// A quantitative genetic take on a model relating robustness to
// evolvability. This version focuses on capacitating epistasis.
// It expects a few arguments to be passed on the command line.
// Run like so:
// slim -d rep=%s -d ps=%s -d q=%s -d -d de=%s Hardy_24_S1.slim

//a membership-testing function
function (logical)isIn(integer y, integer x){ 
	return any(asLogical(match(y, x)+1));
}

initialize() {
	initializeSLiMModelType("nonWF");
	defineConstant("Rep", rep); //replication number [rep]
	defineConstant("X", 1.0); //variance multiplier
	defineConstant("delta", de); //default capacitance
	defineConstant("nu", 0.6); //proportion of m1 alleles modified by new m2 allele 
	defineConstant("tx", 100); //generation at which OX becomes adaptive [100]
	defineConstant("om0", 1.0); //initial weakness of selection [1.0]
	defineConstant("q0", q); //ratio of capacitor to target mutations [q]
	defineConstant("R", 1.5); //birth rate
	defineConstant("P", ps); //the breadth of allele effect distribution [ps]
	defineConstant("O1", 0.0); // phenotype optimum in phase 1
	defineConstant("O2", 5.0); //optimum in phase 2 [6.0]
	defineConstant("K", 500); //size of population
	defineConstant("M", K / (R-1));
	initializeMutationRate(1e-5); //[1e-5]
	initializeMutationType("m1", 0.5, "n", 0.0, P); //target alleles
	initializeMutationType("m2", 0.5, "f", 0.0); //epistatic capacitor alleles
	initializeMutationType("m3", 0.5, "n", 0.0, 1.0); //free alleles
	initializeGenomicElementType("g1", c(m1,m2,m3), c((1.0-q0),q0,0.0));
	initializeGenomicElement(g1, 0, 9999);
	initializeRecombinationRate(1e-6); //[1e-6]
	m1.convertToSubstitution = F;
	m1.mutationStackPolicy = 'l';
	m2.convertToSubstitution = F;
	m2.mutationStackPolicy = 'l';
	m3.convertToSubstitution = F;
	m3.mutationStackPolicy = 'l';
}

mutationEffect(m1) { return 1.0; }
mutationEffect(m2) { return 1.0; }
mutationEffect(m3) { return 1.0; }

//a special mutation callback for capacitor alleles
mutation(m2){ 
	//who's the target
	muts1 = genome.mutationsOfType(m1);
	mut.setValue("Targets", 0);
	mut.setValue("Epi_effects", 1.0);
	if (size(muts1)){
	    numTargets = min(20, max(1, asInteger(round(nu*size(muts1)))));
		targets = sample(muts1, numTargets, replace=F);
		target_loci = targets.position;
		epiEffs = runif(numTargets,-X,X);
		mut.setValue("Targets", target_loci);
		mut.setValue("Epi_effects", epiEffs);
	}
	return T;
}

//simple clonal reproduction
reproduction() {
   fecundity = rpois(1, R);
   for (i in seqLen(fecundity)){
	    offspring = subpop.addCloned(individual);
   }
}

//let's use a modifyChild() callback to calculate the niche phenotype value
//based on the m1 and m2 mutations
modifyChild(){
	muts1 = child.genomes.mutationsOfType(m1);
	muts2 = child.genomes.mutationsOfType(m2);
	muts3 = child.genomes.mutationsOfType(m3);
	pheno = 0.0;
	freeo = size(muts3) ? child.sumOfMutationsOfType(m3) else 0.0;
	for (mi in muts1){
		if (size(muts2)){
			controllers = muts2[sapply(muts2, "isIn(applyValue.getValue('Targets'),mi.position);")];
			if (size(controllers)){
			    epiEff = 0.0;
			    for (mx in controllers){
			        mind = which(mx.getValue("Targets")==mi.position);
			        eE = mx.getValue("Epi_effects")[mind];
			        epiEff = epiEff + eE;
			    }  
				modEff = mi.selectionCoeff * epiEff;
				pheno = pheno + modEff;
			} else {
				pheno = pheno + mi.selectionCoeff*delta;
			}
		} else {
			pheno = pheno + mi.selectionCoeff*delta;
		}
	}
	child.setValue("p", pheno + freeo);
	child.setValue("fr", freeo);
	return T;
}

// set up simple metapopulation
// and give individuals their initial phenotype states
1 early() {
	sim.addSubpop("p1", K);
	sim.subpopulations.individuals.setValue("p", 0.0);
}


//do selection and regulation
1: early(){
	inds = sim.subpopulations.individuals;
	scale = dnorm(0.0, 0.0, om0);
	phenos = inds.getValue("p");
	y = dnorm(inds.getValue("p"), O1, om0)/(1.5*scale);//[1.2]
	z = dnorm(inds.getValue("p"), O2, om0)/scale;
	if (sim.cycle < tx){
		inds.fitnessScaling = y;
	} else {
		inds.fitnessScaling = y + z; //here we combine two normal fitness functions
	}
	n_t_plus_pt5 = sum(inds.age == 0);
	p1.fitnessScaling = 1 / (1 + (n_t_plus_pt5 / R) / M); //Beverton-Holtish density dependence
}

//some logging
100:10000 early(){
	inds = p1.individuals;
	mP1 = mean(inds.getValue("p"));
	mFr = mean(inds.getValue("fr"));
	mW1 = mean(inds.fitnessScaling);
	if (sim.cycle % 10 == 0.0){
		catn(c(sim.cycle, mW1, mP1, mFr));
	}
	writeFile("log.csv", paste(c(Rep,P,q0,rho,delta,sim.cycle,mP1,mW1),sep=','),append=T);
	thresh = 0.25*O2;
	if (abs(mP1-O2) < thresh){
		sim.simulationFinished();
		catn("Nailed it!");
	}
}


